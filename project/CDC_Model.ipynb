{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 186,
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "source": [
    "app_data = pd.read_excel('/Users/yichengzou/Desktop/mobile_app_user_dataset.xlsx')\n",
    "df = pd.DataFrame(app_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "source": [
    "apple = df[df['Q4'] == 1]\n",
    "#apple.to_csv('/Users/yichengzou/Desktop/apple.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "source": [
    "bberry = df[df['Q4'] == 2]\n",
    "#bberry.to_csv('/Users/yichengzou/Desktop/bbery.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "source": [
    "android = df[df['Q4'] == 3]\n",
    "#android.to_csv('/Users/yichengzou/Desktop/android.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "source": [
    "nokia = df[df['Q4'] == 4]\n",
    "#nokia.to_csv('/Users/yichengzou/Desktop/nokia.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "source": [
    "samsung = df[df['Q4'] == 5]\n",
    "#samsung.to_csv('/Users/yichengzou/Desktop/samsung.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "apple = apple[['Q3_1_TEXT', 'Q4', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q25', 'Q26', 'Q27' ]]\n",
    "apple.rename(columns={'Q4':'phone type', 'Q17':'age', 'Q18':'marital status', 'Q19':'nationality', 'Q20':'residence', 'Q22':'ethnicity', 'Q25':'disability', 'Q27':'occupation'}, inplace=True)\n",
    "apple.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "bberry = bberry[['Q3_1_TEXT', 'Q4', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q25', 'Q26', 'Q27' ]]\n",
    "bberry.rename(columns={'Q4':'phone type', 'Q17':'age', 'Q18':'marital status', 'Q19':'nationality', 'Q20':'residence', 'Q22':'ethnicity', 'Q25':'disability', 'Q27':'occupation'}, inplace=True)\n",
    "bberry.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "android = android[['Q3_1_TEXT', 'Q4', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q25', 'Q26', 'Q27'  ]]\n",
    "android.rename(columns={'Q4':'phone type', 'Q17':'age', 'Q18':'marital status', 'Q19':'nationality', 'Q20':'residence', 'Q22':'ethnicity', 'Q25':'disability', 'Q27':'occupation'}, inplace=True)\n",
    "android.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nokia = nokia[['Q3_1_TEXT', 'Q4', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q25', 'Q26', 'Q27'  ]]\n",
    "nokia.rename(columns={'Q4':'phone type', 'Q17':'age', 'Q18':'marital status', 'Q19':'nationality', 'Q20':'residence', 'Q22':'ethnicity', 'Q25':'disability', 'Q27':'occupation'}, inplace=True)\n",
    "nokia.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "samsung = samsung[['Q3_1_TEXT', 'Q4', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q25', 'Q26', 'Q27'  ]]\n",
    "samsung.rename(columns={'Q4':'phone type', 'Q17':'age', 'Q18':'marital status', 'Q19':'nationality', 'Q20':'residence', 'Q22':'ethnicity', 'Q25':'disability', 'Q27':'occupation'}, inplace=True)\n",
    "samsung.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "source": [
    "apple = apple.dropna()\n",
    "bberry = bberry.dropna()\n",
    "android = android.dropna()\n",
    "nokia = nokia.dropna()\n",
    "samsung = samsung.dropna()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "new_data = apple.append(bberry).append(android).append(nokia).append(samsung)\n",
    "new_data"
   ],
   "outputs": [],
   "metadata": {
    "scrolled": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "source": [
    "# importing necessary libraries\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "# loading dataset\n",
    "data = new_data.to_numpy()\n",
    " \n",
    "# X -> features, y -> label\n",
    "X = data[:,2:]\n",
    "y = data[:,1]\n",
    "y = y-1\n",
    "X=X.astype('int')\n",
    "y=y.astype('int')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "SVM linear model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "source": [
    "# dividing X, y into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "source": [
    "# training a linear SVM classifier\n",
    "from sklearn.svm import SVC\n",
    "svm_model_linear = SVC(kernel = 'linear', C = 1).fit(X_train, y_train)\n",
    "svm_predictions = svm_model_linear.predict(X_test)\n",
    " \n",
    "# model accuracy for X_test \n",
    "accuracy = svm_model_linear.score(X_test, y_test)\n",
    " \n",
    "# creating a confusion matrix\n",
    "cm = confusion_matrix(y_test, svm_predictions)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "accuracy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "4-layer neural network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "source": [
    "x, x_val, y, y_val = train_test_split(X, y, test_size=0.33, random_state=42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "source": [
    "x_train = x.reshape(-1, x.shape[1]).astype('float32')\n",
    "y_train = y\n",
    "\n",
    "x_val = x_val.reshape(-1, x_val.shape[1]).astype('float32')\n",
    "y_val = y_val"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "source": [
    "x_val = torch.from_numpy(x_val)\n",
    "y_val = torch.from_numpy(y_val)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class Data(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x=torch.from_numpy(x).type(torch.FloatTensor)\n",
    "        self.y=torch.from_numpy(y).type(torch.LongTensor)\n",
    "        self.len=self.x.shape[0]\n",
    "    def __getitem__(self,index):      \n",
    "        return self.x[index], self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "source": [
    "data_set=Data()\n",
    "trainloader=DataLoader(dataset=data_set,batch_size=10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data_set.x[0:10]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "source": [
    "data_set.x.shape, data_set.y.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([3086, 11]), torch.Size([3086]))"
      ]
     },
     "metadata": {},
     "execution_count": 219
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "source": [
    "## Build Model and train it\n",
    "class Net(nn.Module):\n",
    "    def __init__(self,in_size,n_hidden1,n_hidden2,out_size,p=0):\n",
    "\n",
    "        super(Net,self).__init__()\n",
    "        self.drop=nn.Dropout(p=p)\n",
    "        self.linear1=nn.Linear(in_size,n_hidden1)\n",
    "        nn.init.kaiming_uniform_(self.linear1.weight,nonlinearity='relu')\n",
    "        self.linear2=nn.Linear(n_hidden1,n_hidden2)\n",
    "        nn.init.kaiming_uniform_(self.linear1.weight,nonlinearity='relu')\n",
    "        self.linear3=nn.Linear(n_hidden2,n_hidden2)\n",
    "        nn.init.kaiming_uniform_(self.linear3.weight,nonlinearity='relu')\n",
    "        self.linear4=nn.Linear(n_hidden2,out_size)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.linear1(x))\n",
    "        x=self.drop(x)\n",
    "        x=F.relu(self.linear2(x))\n",
    "        x=self.drop(x)\n",
    "        x=F.relu(self.linear3(x))\n",
    "        x=self.drop(x)\n",
    "        x=self.linear4(x)\n",
    "        return x"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model=Net(11,200,50,5)\n",
    "model_drop=Net(11,200,50,5,p=0.2)\n",
    "model_drop"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_drop.train()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "source": [
    "optimizer_ofit = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "optimizer_drop = torch.optim.Adam(model_drop.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "source": [
    "LOSS={}\n",
    "LOSS['training data no dropout']=[]\n",
    "LOSS['validation data no dropout']=[]\n",
    "LOSS['training data dropout']=[]\n",
    "LOSS['validation data dropout']=[]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n_epochs=20\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for x, y in trainloader:\n",
    "        #make a prediction for both models \n",
    "        yhat = model(data_set.x)\n",
    "        yhat_drop = model_drop(data_set.x)\n",
    "        #calculate the lossf or both models \n",
    "        loss = criterion(yhat, data_set.y)\n",
    "        loss_drop = criterion(yhat_drop, data_set.y)\n",
    "        \n",
    "        #store the loss for  both the training and validation  data for both models \n",
    "        LOSS['training data no dropout'].append(loss.item())\n",
    "        LOSS['training data dropout'].append(loss_drop.item())\n",
    "        model_drop.eval()\n",
    "        model_drop.train()\n",
    "\n",
    "        #clear gradient \n",
    "        optimizer_ofit.zero_grad()\n",
    "        optimizer_drop.zero_grad()\n",
    "        #Backward pass: compute gradient of the loss with respect to all the learnable parameters\n",
    "        loss.backward()\n",
    "        loss_drop.backward()\n",
    "        #the step function on an Optimizer makes an update to its parameters\n",
    "        optimizer_ofit.step()\n",
    "        optimizer_drop.step()\n",
    "        \n",
    "        print('epoch {}, loss {}'.format(epoch, loss.item()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "source": [
    "yhat_val = model_drop(x_val)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "new_yhat_val = np.argmax(yhat_val.detach().numpy(),axis=1)\n",
    "len(new_yhat_val)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "new_y_val = y_val.numpy()\n",
    "new_y_val[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "count = 0\n",
    "for i in range(len(new_y_val)):\n",
    "    if new_yhat_val[i]  == new_y_val[i]:\n",
    "        count+=1\n",
    "print(count/len(new_y_val))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}